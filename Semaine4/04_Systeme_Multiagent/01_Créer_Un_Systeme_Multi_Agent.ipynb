{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d5143b-d5b4-4788-befb-50da4c3f3f97",
   "metadata": {},
   "source": [
    "# Système Multi-Agents : Analyse et Exploitation de Transcriptions YouTube avec GPT-4o\n",
    "\n",
    "Ce système illustre comment **plusieurs agents IA** peuvent collaborer pour réaliser une tâche complexe de manière coordonnée : analyser un contenu (texte ou vidéo YouTube) et produire des réponses ou contenus exploitables.\n",
    "\n",
    "##  Objectifs\n",
    "\n",
    "* **Agent 1 (Analyse)** : extraire les informations clés d’un texte ou d’une transcription vidéo et produire un livrable structuré.\n",
    "* **Agent 2 (Réponse/Rédaction)** : exploiter le livrable d’Agent 1 pour répondre à des questions ou générer des contenus prêts à l’emploi (post LinkedIn, résumé, etc.).\n",
    "* **Orchestrateur** : coordonner le passage de données entre les agents et afficher les résultats intermédiaires et finaux.\n",
    "\n",
    "\n",
    "##  Outils et bibliothèques\n",
    "\n",
    "| Outil / Librairie        | Rôle                                                                       |\n",
    "| ------------------------ | -------------------------------------------------------------------------- |\n",
    "| `youtube_transcript_api` | Récupération des sous-titres (transcriptions) depuis une URL YouTube       |\n",
    "| `agents`                 | Création et exécution des agents IA, déclaration des outils                |\n",
    "| `dotenv`                 | Chargement de la clé OpenAI depuis un fichier `.env` pour plus de sécurité |\n",
    "| `openai.types.responses` | Gestion des réponses complètes ou en streaming                             |\n",
    "| `asyncio`                | Gestion asynchrone du dialogue et des appels agents                        |\n",
    "\n",
    "\n",
    "## Étapes clés\n",
    "\n",
    "### 1. Chargement des variables d’environnement\n",
    "\n",
    "* La clé API OpenAI (`OPENAI_API_KEY`) est lue depuis `.env`.\n",
    "* Sécurise les identifiants en évitant le stockage en clair dans le code.\n",
    "\n",
    "### 2. Définition de l’outil `fetch_youtube_transcript()`\n",
    "\n",
    "* Reçoit une URL YouTube.\n",
    "* Extrait l’ID vidéo.\n",
    "* Utilise `.fetch()` pour récupérer les sous-titres (priorité au français, sinon anglais).\n",
    "* Formate chaque ligne avec `[MM:SS]`.\n",
    "* Accessible aux agents via `@function_tool`.\n",
    "\n",
    "### 3. Agent 1 — Analyse\n",
    "\n",
    "* Entrée : texte brut ou transcript.\n",
    "* Sortie :\n",
    "\n",
    "  1. Points clés (5–8 éléments).\n",
    "  2. Ton & intentions (2–3 phrases).\n",
    "  3. Angles d’approche (2–3 idées).\n",
    "  4. Résumé exécutif (120–180 mots).\n",
    "\n",
    "### 4. Agent 2 — Réponse/Rédaction\n",
    "\n",
    "* Entrée : livrable d’Agent 1 + consigne utilisateur.\n",
    "* Sortie : réponse factuelle ou contenu prêt à publier.\n",
    "\n",
    "### 5. Orchestrateur\n",
    "\n",
    "* Détecte si entrée = URL YouTube ou texte.\n",
    "* Si URL : tente transcript localement.\n",
    "* Lance Agent 1, stocke l’analyse.\n",
    "* Lance Agent 2 avec l’analyse et la consigne.\n",
    "* Affiche les aperçus.\n",
    "\n",
    "\n",
    "\n",
    "##  Flux de données\n",
    "\n",
    "1. **Entrée** : texte ou URL YouTube.\n",
    "2. **Préparation** : récupération transcript si possible.\n",
    "3. **Analyse** (Agent 1) → livrable structuré.\n",
    "4. **Rédaction** (Agent 2) → contenu exploitable.\n",
    "5. **Affichage** : aperçu clair à l’utilisateur.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30efc495-5f84-497e-9044-55549521f816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: bleach 4.1.0 does not provide the extra 'css'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Exécute une fois si nécessaire\n",
    "!pip install python-dotenv youtube-transcript-api openai-agents openai ipywidgets -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23470da-9b3e-44a8-b18a-4ccc8f5ba32a",
   "metadata": {},
   "source": [
    "###  Chargement des bibliothèques essentielles\n",
    "\n",
    "Dans cette section, nous importons toutes les bibliothèques nécessaires au bon fonctionnement de notre agent intelligent :\n",
    "\n",
    "- `re` : pour manipuler les expressions régulières (extraction de l'ID vidéo YouTube)\n",
    "- `asyncio` : pour exécuter l'application de manière asynchrone, sans blocage\n",
    "- `dotenv` : pour charger automatiquement la clé API OpenAI depuis un fichier `.env` sécurisé\n",
    "- `youtube_transcript_api` : pour récupérer les sous-titres (transcription) des vidéos YouTube\n",
    "- `youtube_transcript_api._errors` : pour gérer proprement les erreurs spécifiques à YouTube (ex : vidéo privée, transcription absente, etc.)\n",
    "- `agents` : module local définissant la structure de l’agent, les outils utilisables, et l’exécution des dialogues\n",
    "- `openai.types.responses` : pour gérer les réponses `streamées` du modèle (affichage en temps réel mot par mot)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa33bf-2825-4ef9-a65e-89d7c738b02e",
   "metadata": {},
   "source": [
    "# Importation des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7514679-c195-4bf9-bad3-0f7a26a0d3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2-env/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "\n",
    "# .env (OPENAI_API_KEY)\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Framework agents (comme dans ton projet)\n",
    "from agents import Agent, function_tool, Runner\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "\n",
    "# Transcript YouTube\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import (\n",
    "    NoTranscriptFound, TranscriptsDisabled, VideoUnavailable, CouldNotRetrieveTranscript\n",
    ")\n",
    "\n",
    "# (Optionnel) permet d'utiliser 'await' au niveau cellule sous Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8a67ebc-ae9f-4857-bcd9-88b7b5341df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging                                                   # Permet de configurer les niveaux de journalisation du programme\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)             # Réduit les messages de log HTTPX à WARNING uniquement (supprime les logs INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535570e0-af0d-4208-afe9-caa31c397d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clé API chargée : sk-proj-...\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv                              # Importe la fonction pour charger les variables d’environnement depuis un fichier .env\n",
    "import os                                                   # Permet d’accéder aux variables d’environnement via os.getenv()\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", override=True)              # Charge explicitement le fichier .env et écrase les variables existantes si nécessaire\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")                       # Récupère la clé API OpenAI depuis l’environnement\n",
    "print(\"Clé API chargée :\", api_key[:8] + \"...\" if api_key else \"Aucune clé détectée\")  # Affiche un extrait de la clé ou un message d’erreur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a7beef2-9dff-4960-be55-dfc486a99236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a68a6a2-e3cc-4724-8804-3c63e9b5a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Helper d'extraction (non-streaming)\n",
    "# =========================\n",
    "def extract_run_text(res):\n",
    "    \"\"\"\n",
    "    Extrait le texte final pertinent depuis un objet `RunResult` ou équivalent,\n",
    "    en tenant compte des différentes structures possibles selon la version de la\n",
    "    bibliothèque `agents`.\n",
    "\n",
    "    Cette fonction est conçue pour être robuste face aux variations de format\n",
    "    renvoyées par `Runner.run(...)` ou `Runner.run_streamed(...)`. Elle teste\n",
    "    plusieurs chemins d'accès au texte produit, en suivant cet ordre :\n",
    "\n",
    "    1. **Attributs simples** :\n",
    "       - Recherche dans les attributs courants (`output_text`, `final_output`,\n",
    "         `text`, `output`) si l'un est une chaîne non vide.\n",
    "\n",
    "    2. **Messages \"OpenAI-style\"** :\n",
    "       - Cherche dans `output_messages` ou `messages` une liste de messages.\n",
    "       - Parcourt les messages en sens inverse (du plus récent au plus ancien).\n",
    "       - Si un message contient un champ `content` texte ou une liste de\n",
    "         segments avec `text`, les concatène.\n",
    "\n",
    "    3. **Items** :\n",
    "       - Cherche une liste `items` (ex. sortie détaillée d'un run).\n",
    "       - Parcourt les éléments en sens inverse.\n",
    "       - Repère les éléments de type `message_output_item` et en extrait les\n",
    "         segments texte de `raw_item.content`.\n",
    "\n",
    "    4. **Fallback** :\n",
    "       - Si aucune extraction n'a réussi, renvoie `str(res)` comme valeur de\n",
    "         secours (représentation brute de l'objet).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    res : object\n",
    "        Objet résultat renvoyé par la fonction `Runner.run(...)` ou similaire.\n",
    "        Peut être un `RunResult`, un dict ou un objet contenant les attributs\n",
    "        attendus.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Chaîne extraite contenant le texte final interprétable par l'utilisateur.\n",
    "        Peut être une chaîne vide si aucune donnée textuelle exploitable n'est trouvée.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - La fonction est conçue pour tolérer les changements de structure internes\n",
    "      entre différentes versions de la lib `agents`.\n",
    "    - Si la sortie est complexe (par ex. avec plusieurs parties), elles sont\n",
    "      concaténées avec des sauts de ligne.\n",
    "    \"\"\"\n",
    "    # Tentatives directes\n",
    "    for attr in (\"output_text\", \"final_output\", \"text\", \"output\"):\n",
    "        val = getattr(res, attr, None)\n",
    "        if isinstance(val, str) and val.strip():\n",
    "            return val\n",
    "\n",
    "    # Messages (OpenAI-style)\n",
    "    msgs = getattr(res, \"output_messages\", None) or getattr(res, \"messages\", None)\n",
    "    if isinstance(msgs, list) and msgs:\n",
    "        for m in reversed(msgs):\n",
    "            content = m.get(\"content\") if isinstance(m, dict) else getattr(m, \"content\", None)\n",
    "            if isinstance(content, str) and content.strip():\n",
    "                return content\n",
    "            if isinstance(content, list):\n",
    "                parts = []\n",
    "                for p in content:\n",
    "                    t = p.get(\"text\") if isinstance(p, dict) else getattr(p, \"text\", None)\n",
    "                    if t:\n",
    "                        parts.append(t)\n",
    "                if parts:\n",
    "                    return \"\\n\".join(parts)\n",
    "\n",
    "    # Items (message_output_item)\n",
    "    items = getattr(res, \"items\", None)\n",
    "    if isinstance(items, list) and items:\n",
    "        for it in reversed(items):\n",
    "            it_type = it.get(\"type\") if isinstance(it, dict) else getattr(it, \"type\", None)\n",
    "            if it_type == \"message_output_item\":\n",
    "                raw = it.get(\"raw_item\") if isinstance(it, dict) else getattr(it, \"raw_item\", None)\n",
    "                content = raw.get(\"content\") if isinstance(raw, dict) else getattr(raw, \"content\", None)\n",
    "                if isinstance(content, list):\n",
    "                    parts = []\n",
    "                    for p in content:\n",
    "                        t = p.get(\"text\") if isinstance(p, dict) else getattr(p, \"text\", None)\n",
    "                        if t:\n",
    "                            parts.append(t)\n",
    "                    if parts:\n",
    "                        return \"\\n\".join(parts)\n",
    "\n",
    "    # Fallback\n",
    "    return str(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb81b6f-aa66-425c-b1a9-d099f0c82c45",
   "metadata": {},
   "source": [
    "### Récupération et formatage de la transcription\n",
    "\n",
    "Cette fonction permet d’extraire automatiquement la transcription d’une vidéo YouTube à partir de son URL.  \n",
    "Elle identifie l’ID de la vidéo, interroge l’API via la méthode `.fetch()` et formate le texte avec des horodatages `[MM:SS]`.  \n",
    "Elle prend également en compte les cas d’erreur courants (vidéo privée, transcription désactivée, etc.).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae153bb8-f625-4267-a182-db910c8143ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Transcript (impl Python robuste + outil exposé)\n",
    "# =========================\n",
    "def fetch_youtube_transcript_impl(url: str) -> str:\n",
    "    \"\"\"Récupère la transcription d'une vidéo YouTube et la formate [MM:SS] texte.\n",
    "       Compatible dicts ET objets FetchedTranscriptSnippet.\n",
    "    \"\"\"\n",
    "    video_id_pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*'\n",
    "    match = re.search(video_id_pattern, url or \"\")\n",
    "    if not match:\n",
    "        return \"⚠️ URL YouTube invalide.\"\n",
    "\n",
    "    vid = match.group(1)\n",
    "    try:\n",
    "        ytt_api = YouTubeTranscriptApi()\n",
    "        transcript_data = None\n",
    "\n",
    "        # Priorité fr → en → défaut\n",
    "        try:\n",
    "            transcript_data = ytt_api.fetch(vid, languages=['fr'])\n",
    "        except NoTranscriptFound:\n",
    "            try:\n",
    "                transcript_data = ytt_api.fetch(vid, languages=['en'])\n",
    "            except NoTranscriptFound:\n",
    "                transcript_data = ytt_api.fetch(vid)\n",
    "\n",
    "        if not transcript_data:\n",
    "            return \"❌ Aucune donnée de transcription récupérée\"\n",
    "\n",
    "        lines = []\n",
    "        for entry in transcript_data:\n",
    "            try:\n",
    "                # Cas objet (FetchedTranscriptSnippet)\n",
    "                if hasattr(entry, \"start\") and hasattr(entry, \"text\"):\n",
    "                    start = float(entry.start)\n",
    "                    text = entry.text\n",
    "                # Cas dict (ancien format)\n",
    "                elif isinstance(entry, dict) and \"start\" in entry and \"text\" in entry:\n",
    "                    start = float(entry[\"start\"])\n",
    "                    text = entry[\"text\"]\n",
    "                else:\n",
    "                    # Fallback ultra-robuste\n",
    "                    start = float(getattr(entry, \"start\", 0.0))\n",
    "                    text = str(getattr(entry, \"text\", \"\"))\n",
    "\n",
    "                text = (text or \"\").strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "\n",
    "                m, s = int(start // 60), int(start % 60)\n",
    "                lines.append(f\"[{m:02d}:{s:02d}] {text}\")\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        if not lines:\n",
    "            return \"❌ Transcription vide\"\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    except TranscriptsDisabled:\n",
    "        return \"❌ Les transcriptions sont désactivées pour cette vidéo.\"\n",
    "    except VideoUnavailable:\n",
    "        return \"❌ Vidéo non disponible.\"\n",
    "    except CouldNotRetrieveTranscript:\n",
    "        return \"❌ Impossible de récupérer la transcription.\"\n",
    "    except Exception as e:\n",
    "        return f\"❌ Erreur : {str(e)}\"\n",
    "\n",
    "# Exposer l’outil pour l’agent (function calling)\n",
    "from agents import function_tool\n",
    "fetch_youtube_transcript = function_tool(fetch_youtube_transcript_impl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a722c1-7884-4dcf-b9c9-989983cd771a",
   "metadata": {},
   "source": [
    "##  Agents IA (GPT-5) — Instructions hybrides\n",
    "\n",
    "### Agent 1 — Analyse\n",
    "- **Rôle** : Analyse un texte ou une URL YouTube.\n",
    "- **Si URL** : utilise `fetch_youtube_transcript` pour récupérer le transcript.\n",
    "- **Sortie** :  \n",
    "  1. Points clés (5–8)  \n",
    "  2. Ton & intentions (2–3 phrases)  \n",
    "  3. Angles d’email (2–3 lignes)  \n",
    "  4. Résumé exécutif (120–180 mots)  \n",
    "- **Modèle** : `gpt-5`\n",
    "\n",
    "### Agent 2 — Réponse & Rédaction\n",
    "- **Rôle** : Utilise le transcript et l’analyse pour :\n",
    "  - Répondre à des questions factuelles\n",
    "  - Générer un post LinkedIn (800–1200 car.) ou Instagram (300–600 car.)\n",
    "- **Outils** : aucun  \n",
    "- **Modèle** : `gpt-5`\n",
    "\n",
    "**Flux** : Utilisateur → Agent 1 (analyse) → Agent 2 (réponse ou rédaction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4e0269-efb4-4812-b37b-6db5e466565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#  Agents (GPT-5) avec instructions hybrides\n",
    "# =========================\n",
    "# Agent 1 — Analyse (outil en secours si URL sans transcript)\n",
    "AGENT1_INSTRUCTIONS = (\n",
    "    \"Tu es un analyste éditorial. \"\n",
    "    \"Tu peux recevoir soit un TEXTE directement, soit une URL YouTube. \"\n",
    "    \"Si on te donne une URL YouTube et qu'aucun transcript exploitable n'est fourni dans le message, \"\n",
    "    \"alors appelle l'outil fetch_youtube_transcript(url) pour récupérer le transcript AVANT d'analyser. \"\n",
    "    \"Ensuite, retourne STRICTEMENT les blocs suivants, en français :\\n\"\n",
    "    \"1) Points clés (5–8, liste numérotée)\\n\"\n",
    "    \"2) Ton & intentions de l’auteur (2–3 phrases)\\n\"\n",
    "    \"3) Angles d’email possibles (2–3, une ligne chacun)\\n\"\n",
    "    \"4) Résumé exécutif (120–180 mots)\\n\"\n",
    "    \"Évite les généralités, ancre-toi dans le contenu. Ne rajoute pas d’autre texte.\"\n",
    ")\n",
    "\n",
    "def create_agent_analyse():\n",
    "    return Agent(\n",
    "        name=\"Agent Analyse\",\n",
    "        instructions=AGENT1_INSTRUCTIONS,\n",
    "        tools=[fetch_youtube_transcript],  # ✅ outil dispo en backup\n",
    "        model=\"gpt-5\",\n",
    "    )\n",
    "\n",
    "# Agent 2 — Réponse & Rédaction\n",
    "AGENT2_INSTRUCTIONS = (\n",
    "    \"Tu es un assistant de réponses et de rédaction. On te donne :\\n\"\n",
    "    \"- le transcript ou le texte source (si disponible)\\n\"\n",
    "    \"- le livrable de l’Agent Analyse (points clés, ton, angles, résumé)\\n\"\n",
    "    \"Tu dois :\\n\"\n",
    "    \"1) Répondre aux questions factuelles de l’utilisateur en t’appuyant sur le contenu, OU\\n\"\n",
    "    \"2) Générer des contenus courts (post LinkedIn 800–1200 car., post Instagram 300–600 car.).\\n\"\n",
    "    \"Reste concret et fidèle au contenu.\"\n",
    ")\n",
    "\n",
    "def create_agent_responder():\n",
    "    return Agent(\n",
    "        name=\"Agent Réponse & Rédaction\",\n",
    "        instructions=AGENT2_INSTRUCTIONS,\n",
    "        tools=[],  # pas d’outil ici\n",
    "        model=\"gpt-5\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0613404-9f71-4d8c-bd3b-092ddfdbc908",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9b02b6e-5691-4519-8ebd-ddfee03be50c",
   "metadata": {},
   "source": [
    "### Lancement de la boucle de dialogue avec l'utilisateur\n",
    "\n",
    "La fonction `main()` initialise et gère l’interaction en continu entre l'utilisateur et l'agent.\n",
    "\n",
    "#### Fonctionnement :\n",
    "- Affiche un message d’accueil et attend une entrée utilisateur\n",
    "- Gère les commandes de sortie (`exit`, `quit`, etc.)\n",
    "- Stocke les échanges dans une liste `input_items` pour maintenir le contexte\n",
    "- Limite l’historique à 8 messages pour éviter les dépassements de capacité du modèle (token limit)\n",
    "- Transmet les échanges à l’agent via `Runner.run_streamed(...)` pour obtenir une réponse en streaming\n",
    "- Gère les différents types d’événements retournés : texte généré, appel d’outil, résultats d’outil\n",
    "- Affiche la réponse en temps réel ligne par ligne\n",
    "\n",
    "Cette boucle permet de simuler une véritable conversation, tout en exploitant les capacités du modèle GPT-4o et de l’outil `fetch_youtube_transcript` si nécessaire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46fa45f-00e9-487d-bee7-92aff63cc13d",
   "metadata": {},
   "source": [
    "# Orchestrateur :\n",
    " - SessionState : stocke transcript, analyse, type de source\n",
    " - prepare_source : récupère transcript côté Python si possible, sinon garde texte brut\n",
    " - run_analysis_pipeline : lance Agent 1 (analyse) avec transcript ou URL\n",
    " - ask_with_context : lance Agent 2 (réponse/rédaction) avec transcript + analyse + demande\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5498a1c-1429-4420-bb76-fdb34857d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#  Orchestration automatique (analyse + livrables)\n",
    "# =========================\n",
    "\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "def force_json_prompt():\n",
    "    return (\n",
    "        \"Tu dois produire STRICTEMENT un JSON compact (une seule ligne), sans commentaire, sans texte avant/après.\\n\"\n",
    "        \"Schéma attendu:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"points_cles\": [\"\", \"\", \"\", \"\", \"\"],\\n'\n",
    "        '  \"post_linkedin\": \"\"\\n'\n",
    "        \"}\\n\"\n",
    "        \"- points_cles : exactement 5 éléments, concis, factuels, fidèles au contenu d’Agent 1.\\n\"\n",
    "        \"- post_linkedin : ~900 caractères, français, structuré (accroche, développement, conclusion/CTA), lisible, sans hashtags superflus.\\n\"\n",
    "        \"Ne renvoie surtout pas de Markdown ni de texte hors JSON.\"\n",
    "    )\n",
    "\n",
    "async def run_full_pipeline(text_or_url: str):\n",
    "    # 1) Analyse (Agent 1)\n",
    "    analysis = await run_analysis_pipeline(text_or_url)\n",
    "    if not analysis or analysis.startswith(\"❌\"):\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error\": analysis or \"Analyse vide.\",\n",
    "            \"points_cles\": [],\n",
    "            \"post_linkedin\": \"\"\n",
    "        }\n",
    "\n",
    "    # 2) Agent 2 — consigne stricte pour renvoyer un JSON (points_cles + post_linkedin)\n",
    "    strict_json_instr = force_json_prompt()\n",
    "    user_task = (\n",
    "        \"À partir du transcript/texte et de l'analyse ci-dessus, fais ceci :\\n\"\n",
    "        \"1) Donne-moi un résumé clair en **5 points** (courts, factuels, sans jargon inutile).\\n\"\n",
    "        \"2) Propose un **post LinkedIn** autour de 900 caractères, structuré (accroche → idée centrale → appel à l’action), ton pro, sans emojis excessifs.\\n\\n\"\n",
    "        \"Respecte le format JSON imposé ci-dessous.\"\n",
    "    )\n",
    "    full_context = (\n",
    "        \"=== TRANSCRIPT / TEXTE ===\\n\" + (state.transcript[:12000] or \"\") + \"\\n\\n\"\n",
    "        \"=== ANALYSE (Agent 1) ===\\n\" + (analysis[:12000] or \"\") + \"\\n\\n\"\n",
    "        \"=== DEMANDE UTILISATEUR ===\\n\" + user_task + \"\\n\\n\"\n",
    "        \"=== FORMAT ===\\n\" + strict_json_instr\n",
    "    )\n",
    "\n",
    "    res = await Runner.run(\n",
    "        create_agent_responder(),\n",
    "        input=[{\"role\": \"user\", \"content\": full_context}]\n",
    "    )\n",
    "    raw = extract_run_text(res).strip()\n",
    "\n",
    "    # 3) Parsing JSON robuste (tolérance aux entêtes/markdown)\n",
    "    def try_extract_json(s: str):\n",
    "        # essaie de trouver le premier { ... } équilibré\n",
    "        start = s.find(\"{\")\n",
    "        end = s.rfind(\"}\")\n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            candidate = s[start:end+1].strip()\n",
    "            try:\n",
    "                return json.loads(candidate)\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        # dernier recours : tenter directement\n",
    "        try:\n",
    "            return json.loads(s)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    payload = try_extract_json(raw)\n",
    "    if not payload or not isinstance(payload, dict):\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error\": \"Sortie Agent 2 non parsable en JSON.\",\n",
    "            \"raw\": raw,\n",
    "            \"points_cles\": [],\n",
    "            \"post_linkedin\": \"\"\n",
    "        }\n",
    "\n",
    "    points = payload.get(\"points_cles\") or []\n",
    "    post = payload.get(\"post_linkedin\") or \"\"\n",
    "    if not isinstance(points, list):\n",
    "        points = []\n",
    "    if not isinstance(post, str):\n",
    "        post = \"\"\n",
    "\n",
    "    return {\n",
    "        \"status\": \"ok\",\n",
    "        \"analysis_excerpt\": analysis[:1200],\n",
    "        \"points_cles\": points[:5],  # on limite à 5 si plus\n",
    "        \"post_linkedin\": post.strip()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bccb551b-402e-40e6-ba02-43ba35685b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_analysis_pipeline(text_or_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Lance l'analyse avec Agent 1.\n",
    "    - Si transcript Python disponible, l'utilise directement\n",
    "    - Sinon, passe l'URL brute pour que l'agent appelle l'outil\n",
    "    - Retourne les 4 blocs attendus et les stocke dans state.analysis\n",
    "    \"\"\"\n",
    "    user_msg = (text_or_url or \"\").strip()\n",
    "    if not user_msg:\n",
    "        return \"❌ Aucun contenu.\"\n",
    "\n",
    "    # Prépare la source : transcript ou texte brut\n",
    "    source_text = prepare_source(user_msg)\n",
    "    a1 = create_agent_analyse()\n",
    "\n",
    "    # Cas A : transcript récupéré côté Python\n",
    "    if source_text and not source_text.startswith((\"❌\", \"⚠️\")):\n",
    "        prompt = f\"Analyse ce contenu et renvoie les 4 blocs demandés :\\n\\n{source_text}\"\n",
    "        items = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    else:\n",
    "        # Cas B : aucun transcript → l'agent devra appeler l’outil\n",
    "        items = [{\"role\": \"user\", \"content\": user_msg}]\n",
    "\n",
    "    # Exécution (non-streaming)\n",
    "    res = await Runner.run(a1, input=items)\n",
    "    analysis = extract_run_text(res).strip()\n",
    "\n",
    "    # Stockage\n",
    "    state.analysis = analysis if analysis else None\n",
    "    return analysis if analysis else \"❌ Analyse vide.\"\n",
    "\n",
    "\n",
    "async def ask_with_context(user_question_or_task: str) -> str:\n",
    "    \"\"\"\n",
    "    Lance Agent 2 pour répondre ou rédiger à partir :\n",
    "    - du transcript ou texte brut\n",
    "    - de l'analyse produite par Agent 1\n",
    "    - de la question / consigne utilisateur\n",
    "    \"\"\"\n",
    "    if not state.transcript:\n",
    "        return \"❌ Aucun transcript/texte source disponible. Lance d’abord l’analyse.\"\n",
    "    if not state.analysis:\n",
    "        return \"❌ Aucune analyse disponible. Lance d’abord l’analyse.\"\n",
    "\n",
    "    a2 = create_agent_responder()\n",
    "\n",
    "    # Construit le contexte complet\n",
    "    context = (\n",
    "        \"=== TRANSCRIPT / TEXTE ===\\n\" + (state.transcript[:12000] or \"\") + \"\\n\\n\"\n",
    "        \"=== ANALYSE (Agent 1) ===\\n\" + (state.analysis[:12000] or \"\") + \"\\n\\n\"\n",
    "        \"=== DEMANDE UTILISATEUR ===\\n\" + (user_question_or_task or \"\")\n",
    "    )\n",
    "\n",
    "    # Exécution (non-streaming)\n",
    "    res = await Runner.run(a2, input=[{\"role\": \"user\", \"content\": context}])\n",
    "    return extract_run_text(res).strip() or \"❌ Réponse vide.\"\n",
    "\n",
    "\n",
    "class SessionState:\n",
    "    def __init__(self):\n",
    "        self.transcript = None   # texte transcript/texte brut retenu\n",
    "        self.analysis = None     # sortie Agent 1\n",
    "        self.source_kind = None  # \"url\" ou \"text\"\n",
    "\n",
    "state = SessionState()\n",
    "\n",
    "\n",
    "def is_youtube_url(s: str) -> bool:\n",
    "    \"\"\"Détecte si une chaîne est une URL YouTube.\"\"\"\n",
    "    return bool(s) and (\"youtu.be/\" in s or \"youtube.com/watch\" in s)\n",
    "\n",
    "\n",
    "def prepare_source(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Prépare la source pour l'analyse.\n",
    "    - Si URL YouTube → tente de récupérer transcript côté Python\n",
    "    - Sinon → texte brut\n",
    "    \"\"\"\n",
    "    user_input = (user_input or \"\").strip()\n",
    "    if not user_input:\n",
    "        return \"\"\n",
    "\n",
    "    if is_youtube_url(user_input):\n",
    "        state.source_kind = \"url\"\n",
    "        # Ici, on appelle ton implémentation Python directe de transcript\n",
    "        txt = fetch_youtube_transcript_impl(user_input)  \n",
    "        state.transcript = txt\n",
    "        return txt\n",
    "\n",
    "    state.source_kind = \"text\"\n",
    "    state.transcript = user_input\n",
    "    return user_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c8479a-ffb1-45ea-908f-94884669de86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALYSE (Agent 1) — extrait ===\n",
      "1) Points clés\n",
      "1. Trois tests concrets sur un dataset de churn: analyse exploratoire, modélisation ML, et création d’une app Shiny “end-to-end”.\n",
      "2. Test 1 (analyse): GPT‑5 a importé la data (pandas), fait des stats descriptives, tenté un modèle baseline, identifié des drivers (géographie, activité, âge, genre) et fourni un rapport Excel; mais peu de visualisations et confusion initiale sur la cible; note: 5/10. Claude 4.1: livrable visuellement séduisant mais analyses manquantes.\n",
      "3. Test 2 (modélisation): GPT‑5 a livré un pipeline Python (OneHotEncoder, StandardScaler, LogisticRegression), split stratifié, score ~83,7% en test, export du modèle en .joblib + README de déploiement, et propose d’essayer d’autres algos; note: 5/10 (rapport et justifications insuffisants). Claude: surtout de l’HTML/design et une liste d’algos, pas d’exécution; 1/10 “pour la beauté”.\n",
      "4. Test 3 (app Shiny R): structure complète (import, EDA, prétraitement, modélisation, évaluation, explicabilité, scoring, export). Les deux IA génèrent du code mais butent sur des erreurs; GPT‑5 corrige après indications, problèmes de packages; Claude atteint des limites de longueur et n’achève pas sans guidage.\n",
      "5. Constat:\n",
      "\n",
      "=== RÉPONSE (Agent 2) — extrait ===\n",
      "Voici le résumé en 5 points:\n",
      "- Dispositif: cas réel de churn, 3 tâches (analyse exploratoire, modélisation, app Shiny), d’abord sans consignes puis avec; comparaison GPT‑5 vs Claude 4.1.\n",
      "- Analyse exploratoire: GPT‑5 génère code Python (pandas), descriptifs et quelques viz mais hésite sur la cible; rapport perfectible → 5/10. Claude: rendu joli, peu d’insights actionnables.\n",
      "- Modélisation: GPT‑5 livre un pipeline (OneHotEncoder+StandardScaler+LogisticRegression), split stratifié, ~83,7% en test, export .joblib + README → utile mais rapport et justifs faibles → 5/10. Claude: surtout du design/HTML → 1/10.\n",
      "- App Shiny end‑to‑end: les deux produisent du code, mais erreurs, dépendances et besoin de guidage; pas “production ready” sans expertise.\n",
      "- Verdict: l’IA accélère et démocratise, mais ne remplace pas la rigueur/méthodo/stratégie d’un·e expert·e. Le code devient une commodité; la valeur est dans le cadrage, l’évaluation, l’explicabilité et le déploiement. Suite: vidéo mode agentique + Bootcamp GNI Pro (8 semaines dès le 15/09).\n",
      "\n",
      "Post LinkedIn (~900 caractères):\n",
      "GPT‑5 va‑t‑il remplacer les data analysts/scientists ? Je l’ai testé sur un vrai cas de churn, face à Claude 4.1, sur 3 tâches (sans consignes puis guidées): EDA, modélisation, app Shiny end‑to‑end.\n",
      "\n",
      "Résultats:\n",
      "- EDA: GPT‑5 produit code (pandas) et descriptifs, mais hésite sur la cible et peu de viz → 5/10. Claude: beau rendu, peu d’insights.\n",
      "- Modélisation: pipeline (OneHotEncoder+StandardScaler+LogisticRegression), split stratifié, ~83,7% en test, export .joblib + README → utile mais rapport pauvre → 5/10. Claude:\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Démo rapide\n",
    "# =========================\n",
    "SOURCE_INPUT = \"https://www.youtube.com/watch?v=vOmo-Q7RrRc&t=643s\"  # remplace par une URL transcriptible ou colle un texte\n",
    "\n",
    "analysis = await run_analysis_pipeline(SOURCE_INPUT)\n",
    "print(\"=== ANALYSE (Agent 1) — extrait ===\")\n",
    "print((analysis or \"\")[:1200])\n",
    "\n",
    "QUESTION_OR_TASK = \"Donne-moi un résumé clair en 5 points, puis propose un post LinkedIn (~900 caractères).\"\n",
    "answer = await ask_with_context(QUESTION_OR_TASK)\n",
    "print(\"\\n=== RÉPONSE (Agent 2) — extrait ===\")\n",
    "print((answer or \"\")[:1600])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db1009-db50-490f-99d9-4347d2763b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multi-Agents YouTube — GPT-4o (non-streaming) ===\n",
      "Collez une URL YouTube (ou un texte long) → je lance l’analyse + points clés + post LinkedIn automatiquement.\n",
      "Ensuite, tapez une courte question/consigne → je réponds avec l’Agent 2.\n",
      "Tapez 'exit' pour quitter.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  https://www.youtube.com/watch?v=7-FFFjlLwos\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 💬 Cellule 8 — Mini chat (AUTO orchestration)\n",
    "# =========================\n",
    "import textwrap\n",
    "\n",
    "DEBUG = True\n",
    "MAX_PREVIEW = 1500\n",
    "\n",
    "def _looks_like_url(s: str) -> bool:\n",
    "    s = (s or \"\").strip().lower()\n",
    "    return s.startswith(\"http://\") or s.startswith(\"https://\")\n",
    "\n",
    "def _is_youtube_url(s: str) -> bool:\n",
    "    s = (s or \"\").strip().lower()\n",
    "    return \"youtu.be/\" in s or \"youtube.com/watch\" in s\n",
    "\n",
    "def _looks_like_long_text(s: str) -> bool:\n",
    "    # Heuristique simple pour déclencher l'analyse sur un texte “long”\n",
    "    return len((s or \"\").strip()) >= 200\n",
    "\n",
    "async def chat_loop():\n",
    "    print(\"=== Multi-Agents YouTube — GPT-5 ===\")\n",
    "    print(\"Collez une URL YouTube (ou un texte long) → je lance l’analyse + points clés + post LinkedIn automatiquement.\")\n",
    "    print(\"Ensuite, tapez une courte question/consigne → je réponds avec l’Agent 2.\")\n",
    "    print(\"Tapez 'exit' pour quitter.\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user = await asyncio.to_thread(input, \"\\nYou: \")\n",
    "        except (EOFError, KeyboardInterrupt):\n",
    "            print(\"\\nBye.\")\n",
    "            break\n",
    "\n",
    "        if not user:\n",
    "            continue\n",
    "        cmd_raw = user.strip()\n",
    "        cmd = cmd_raw.lower()\n",
    "\n",
    "        # Quitter\n",
    "        if cmd in (\"exit\", \"quit\", \"bye\"):\n",
    "            print(\"👋 À bientôt !\")\n",
    "            break\n",
    "\n",
    "        # 1) Si c'est une URL (YouTube ou autre) OU un texte suffisamment long → orchestration complète\n",
    "        if _looks_like_url(cmd_raw) or _is_youtube_url(cmd_raw) or _looks_like_long_text(cmd_raw):\n",
    "            # Orchestration automatique (Agent 1 → Agent 2)\n",
    "            result = await run_full_pipeline(cmd_raw)\n",
    "            if result.get(\"status\") != \"ok\":\n",
    "                print(\"❌ Pipeline échoué :\", result.get(\"error\", \"Erreur inconnue\"))\n",
    "                if result.get(\"raw\"):\n",
    "                    print(\"\\n--- Sortie brute Agent 2 (debug) ---\\n\")\n",
    "                    print(result[\"raw\"][:2000])\n",
    "            else:\n",
    "                print(\"\\n=== Agent 1 — Analyse (extrait) ===\")\n",
    "                print(result[\"analysis_excerpt\"])\n",
    "\n",
    "                print(\"\\n=== Agent 2 — Résultat 1/2 : Points clés ===\")\n",
    "                if result[\"points_cles\"]:\n",
    "                    for i, p in enumerate(result[\"points_cles\"], 1):\n",
    "                        print(f\"{i}. {p}\")\n",
    "                else:\n",
    "                    print(\"Aucun point clé parsé.\")\n",
    "\n",
    "                print(\"\\n=== Agent 2 — Résultat 2/2 : Post LinkedIn (~900 car.) ===\")\n",
    "                if result[\"post_linkedin\"]:\n",
    "                    print(textwrap.fill(result[\"post_linkedin\"], width=100))\n",
    "                else:\n",
    "                    print(\"Post LinkedIn vide ou non parsé.\")\n",
    "            continue\n",
    "\n",
    "        # 2) Sinon : courte question/consigne → Agent 2 (si on a déjà une analyse)\n",
    "        if state.transcript and state.analysis:\n",
    "            resp = await ask_with_context(cmd_raw)\n",
    "            if resp.startswith(\"❌\"):\n",
    "                print(\"\\n[Agent 2 — ERREUR]\")\n",
    "                print(resp)\n",
    "            else:\n",
    "                print(\"\\n[Agent 2 — RÉPONSE] (aperçu)\")\n",
    "                print(resp[:MAX_PREVIEW] + (\"\\n…[tronqué]\" if len(resp) > MAX_PREVIEW else \"\"))\n",
    "        else:\n",
    "            print(\"\\nℹ️ Collez d’abord une URL YouTube (ou un texte long ≥ 200 caractères).\")\n",
    "            print(\"Je lancerai automatiquement l’analyse + les points clés + le post LinkedIn.\")\n",
    "\n",
    "# Lance la boucle :\n",
    "await chat_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335108d-a266-409d-9022-9674573c5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e9738-e5de-4b49-93e4-540e3683c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pipreqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f2ce8-fcff-4ba1-a977-657a311e2cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b25f2-3029-4a3b-8874-c6db9a3d9479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2-env)",
   "language": "python",
   "name": "tf2-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
