{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d5143b-d5b4-4788-befb-50da4c3f3f97",
   "metadata": {},
   "source": [
    "# SystÃ¨me Multi-Agents : Analyse et Exploitation de Transcriptions YouTube avec GPT-4o\n",
    "\n",
    "Ce systÃ¨me illustre comment **plusieurs agents IA** peuvent collaborer pour rÃ©aliser une tÃ¢che complexe de maniÃ¨re coordonnÃ©e : analyser un contenu (texte ou vidÃ©o YouTube) et produire des rÃ©ponses ou contenus exploitables.\n",
    "\n",
    "##  Objectifs\n",
    "\n",
    "* **Agent 1 (Analyse)** : extraire les informations clÃ©s dâ€™un texte ou dâ€™une transcription vidÃ©o et produire un livrable structurÃ©.\n",
    "* **Agent 2 (RÃ©ponse/RÃ©daction)** : exploiter le livrable dâ€™Agent 1 pour rÃ©pondre Ã  des questions ou gÃ©nÃ©rer des contenus prÃªts Ã  lâ€™emploi (post LinkedIn, rÃ©sumÃ©, etc.).\n",
    "* **Orchestrateur** : coordonner le passage de donnÃ©es entre les agents et afficher les rÃ©sultats intermÃ©diaires et finaux.\n",
    "\n",
    "\n",
    "##  Outils et bibliothÃ¨ques\n",
    "\n",
    "| Outil / Librairie        | RÃ´le                                                                       |\n",
    "| ------------------------ | -------------------------------------------------------------------------- |\n",
    "| `youtube_transcript_api` | RÃ©cupÃ©ration des sous-titres (transcriptions) depuis une URL YouTube       |\n",
    "| `agents`                 | CrÃ©ation et exÃ©cution des agents IA, dÃ©claration des outils                |\n",
    "| `dotenv`                 | Chargement de la clÃ© OpenAI depuis un fichier `.env` pour plus de sÃ©curitÃ© |\n",
    "| `openai.types.responses` | Gestion des rÃ©ponses complÃ¨tes ou en streaming                             |\n",
    "| `asyncio`                | Gestion asynchrone du dialogue et des appels agents                        |\n",
    "\n",
    "\n",
    "## Ã‰tapes clÃ©s\n",
    "\n",
    "### 1. Chargement des variables dâ€™environnement\n",
    "\n",
    "* La clÃ© API OpenAI (`OPENAI_API_KEY`) est lue depuis `.env`.\n",
    "* SÃ©curise les identifiants en Ã©vitant le stockage en clair dans le code.\n",
    "\n",
    "### 2. DÃ©finition de lâ€™outil `fetch_youtube_transcript()`\n",
    "\n",
    "* ReÃ§oit une URL YouTube.\n",
    "* Extrait lâ€™ID vidÃ©o.\n",
    "* Utilise `.fetch()` pour rÃ©cupÃ©rer les sous-titres (prioritÃ© au franÃ§ais, sinon anglais).\n",
    "* Formate chaque ligne avec `[MM:SS]`.\n",
    "* Accessible aux agents via `@function_tool`.\n",
    "\n",
    "### 3. Agent 1 â€” Analyse\n",
    "\n",
    "* EntrÃ©e : texte brut ou transcript.\n",
    "* Sortie :\n",
    "\n",
    "  1. Points clÃ©s (5â€“8 Ã©lÃ©ments).\n",
    "  2. Ton & intentions (2â€“3 phrases).\n",
    "  3. Angles dâ€™approche (2â€“3 idÃ©es).\n",
    "  4. RÃ©sumÃ© exÃ©cutif (120â€“180 mots).\n",
    "\n",
    "### 4. Agent 2 â€” RÃ©ponse/RÃ©daction\n",
    "\n",
    "* EntrÃ©e : livrable dâ€™Agent 1 + consigne utilisateur.\n",
    "* Sortie : rÃ©ponse factuelle ou contenu prÃªt Ã  publier.\n",
    "\n",
    "### 5. Orchestrateur\n",
    "\n",
    "* DÃ©tecte si entrÃ©e = URL YouTube ou texte.\n",
    "* Si URL : tente transcript localement.\n",
    "* Lance Agent 1, stocke lâ€™analyse.\n",
    "* Lance Agent 2 avec lâ€™analyse et la consigne.\n",
    "* Affiche les aperÃ§us.\n",
    "\n",
    "\n",
    "\n",
    "##  Flux de donnÃ©es\n",
    "\n",
    "1. **EntrÃ©e** : texte ou URL YouTube.\n",
    "2. **PrÃ©paration** : rÃ©cupÃ©ration transcript si possible.\n",
    "3. **Analyse** (Agent 1) â†’ livrable structurÃ©.\n",
    "4. **RÃ©daction** (Agent 2) â†’ contenu exploitable.\n",
    "5. **Affichage** : aperÃ§u clair Ã  lâ€™utilisateur.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30efc495-5f84-497e-9044-55549521f816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: bleach 4.1.0 does not provide the extra 'css'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ExÃ©cute une fois si nÃ©cessaire\n",
    "!pip install python-dotenv youtube-transcript-api openai-agents openai ipywidgets -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23470da-9b3e-44a8-b18a-4ccc8f5ba32a",
   "metadata": {},
   "source": [
    "###  Chargement des bibliothÃ¨ques essentielles\n",
    "\n",
    "Dans cette section, nous importons toutes les bibliothÃ¨ques nÃ©cessaires au bon fonctionnement de notre agent intelligent :\n",
    "\n",
    "- `re` : pour manipuler les expressions rÃ©guliÃ¨res (extraction de l'ID vidÃ©o YouTube)\n",
    "- `asyncio` : pour exÃ©cuter l'application de maniÃ¨re asynchrone, sans blocage\n",
    "- `dotenv` : pour charger automatiquement la clÃ© API OpenAI depuis un fichier `.env` sÃ©curisÃ©\n",
    "- `youtube_transcript_api` : pour rÃ©cupÃ©rer les sous-titres (transcription) des vidÃ©os YouTube\n",
    "- `youtube_transcript_api._errors` : pour gÃ©rer proprement les erreurs spÃ©cifiques Ã  YouTube (ex : vidÃ©o privÃ©e, transcription absente, etc.)\n",
    "- `agents` : module local dÃ©finissant la structure de lâ€™agent, les outils utilisables, et lâ€™exÃ©cution des dialogues\n",
    "- `openai.types.responses` : pour gÃ©rer les rÃ©ponses `streamÃ©es` du modÃ¨le (affichage en temps rÃ©el mot par mot)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa33bf-2825-4ef9-a65e-89d7c738b02e",
   "metadata": {},
   "source": [
    "# Importation des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7514679-c195-4bf9-bad3-0f7a26a0d3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2-env/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "\n",
    "# .env (OPENAI_API_KEY)\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Framework agents (comme dans ton projet)\n",
    "from agents import Agent, function_tool, Runner\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "\n",
    "# Transcript YouTube\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import (\n",
    "    NoTranscriptFound, TranscriptsDisabled, VideoUnavailable, CouldNotRetrieveTranscript\n",
    ")\n",
    "\n",
    "# (Optionnel) permet d'utiliser 'await' au niveau cellule sous Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8a67ebc-ae9f-4857-bcd9-88b7b5341df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging                                                   # Permet de configurer les niveaux de journalisation du programme\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)             # RÃ©duit les messages de log HTTPX Ã  WARNING uniquement (supprime les logs INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535570e0-af0d-4208-afe9-caa31c397d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClÃ© API chargÃ©e : sk-proj-...\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv                              # Importe la fonction pour charger les variables dâ€™environnement depuis un fichier .env\n",
    "import os                                                   # Permet dâ€™accÃ©der aux variables dâ€™environnement via os.getenv()\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", override=True)              # Charge explicitement le fichier .env et Ã©crase les variables existantes si nÃ©cessaire\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")                       # RÃ©cupÃ¨re la clÃ© API OpenAI depuis lâ€™environnement\n",
    "print(\"ClÃ© API chargÃ©e :\", api_key[:8] + \"...\" if api_key else \"Aucune clÃ© dÃ©tectÃ©e\")  # Affiche un extrait de la clÃ© ou un message dâ€™erreur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a7beef2-9dff-4960-be55-dfc486a99236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a68a6a2-e3cc-4724-8804-3c63e9b5a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Helper d'extraction (non-streaming)\n",
    "# =========================\n",
    "def extract_run_text(res):\n",
    "    \"\"\"\n",
    "    Extrait le texte final pertinent depuis un objet `RunResult` ou Ã©quivalent,\n",
    "    en tenant compte des diffÃ©rentes structures possibles selon la version de la\n",
    "    bibliothÃ¨que `agents`.\n",
    "\n",
    "    Cette fonction est conÃ§ue pour Ãªtre robuste face aux variations de format\n",
    "    renvoyÃ©es par `Runner.run(...)` ou `Runner.run_streamed(...)`. Elle teste\n",
    "    plusieurs chemins d'accÃ¨s au texte produit, en suivant cet ordre :\n",
    "\n",
    "    1. **Attributs simples** :\n",
    "       - Recherche dans les attributs courants (`output_text`, `final_output`,\n",
    "         `text`, `output`) si l'un est une chaÃ®ne non vide.\n",
    "\n",
    "    2. **Messages \"OpenAI-style\"** :\n",
    "       - Cherche dans `output_messages` ou `messages` une liste de messages.\n",
    "       - Parcourt les messages en sens inverse (du plus rÃ©cent au plus ancien).\n",
    "       - Si un message contient un champ `content` texte ou une liste de\n",
    "         segments avec `text`, les concatÃ¨ne.\n",
    "\n",
    "    3. **Items** :\n",
    "       - Cherche une liste `items` (ex. sortie dÃ©taillÃ©e d'un run).\n",
    "       - Parcourt les Ã©lÃ©ments en sens inverse.\n",
    "       - RepÃ¨re les Ã©lÃ©ments de type `message_output_item` et en extrait les\n",
    "         segments texte de `raw_item.content`.\n",
    "\n",
    "    4. **Fallback** :\n",
    "       - Si aucune extraction n'a rÃ©ussi, renvoie `str(res)` comme valeur de\n",
    "         secours (reprÃ©sentation brute de l'objet).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    res : object\n",
    "        Objet rÃ©sultat renvoyÃ© par la fonction `Runner.run(...)` ou similaire.\n",
    "        Peut Ãªtre un `RunResult`, un dict ou un objet contenant les attributs\n",
    "        attendus.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        ChaÃ®ne extraite contenant le texte final interprÃ©table par l'utilisateur.\n",
    "        Peut Ãªtre une chaÃ®ne vide si aucune donnÃ©e textuelle exploitable n'est trouvÃ©e.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - La fonction est conÃ§ue pour tolÃ©rer les changements de structure internes\n",
    "      entre diffÃ©rentes versions de la lib `agents`.\n",
    "    - Si la sortie est complexe (par ex. avec plusieurs parties), elles sont\n",
    "      concatÃ©nÃ©es avec des sauts de ligne.\n",
    "    \"\"\"\n",
    "    # Tentatives directes\n",
    "    for attr in (\"output_text\", \"final_output\", \"text\", \"output\"):\n",
    "        val = getattr(res, attr, None)\n",
    "        if isinstance(val, str) and val.strip():\n",
    "            return val\n",
    "\n",
    "    # Messages (OpenAI-style)\n",
    "    msgs = getattr(res, \"output_messages\", None) or getattr(res, \"messages\", None)\n",
    "    if isinstance(msgs, list) and msgs:\n",
    "        for m in reversed(msgs):\n",
    "            content = m.get(\"content\") if isinstance(m, dict) else getattr(m, \"content\", None)\n",
    "            if isinstance(content, str) and content.strip():\n",
    "                return content\n",
    "            if isinstance(content, list):\n",
    "                parts = []\n",
    "                for p in content:\n",
    "                    t = p.get(\"text\") if isinstance(p, dict) else getattr(p, \"text\", None)\n",
    "                    if t:\n",
    "                        parts.append(t)\n",
    "                if parts:\n",
    "                    return \"\\n\".join(parts)\n",
    "\n",
    "    # Items (message_output_item)\n",
    "    items = getattr(res, \"items\", None)\n",
    "    if isinstance(items, list) and items:\n",
    "        for it in reversed(items):\n",
    "            it_type = it.get(\"type\") if isinstance(it, dict) else getattr(it, \"type\", None)\n",
    "            if it_type == \"message_output_item\":\n",
    "                raw = it.get(\"raw_item\") if isinstance(it, dict) else getattr(it, \"raw_item\", None)\n",
    "                content = raw.get(\"content\") if isinstance(raw, dict) else getattr(raw, \"content\", None)\n",
    "                if isinstance(content, list):\n",
    "                    parts = []\n",
    "                    for p in content:\n",
    "                        t = p.get(\"text\") if isinstance(p, dict) else getattr(p, \"text\", None)\n",
    "                        if t:\n",
    "                            parts.append(t)\n",
    "                    if parts:\n",
    "                        return \"\\n\".join(parts)\n",
    "\n",
    "    # Fallback\n",
    "    return str(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb81b6f-aa66-425c-b1a9-d099f0c82c45",
   "metadata": {},
   "source": [
    "### RÃ©cupÃ©ration et formatage de la transcription\n",
    "\n",
    "Cette fonction permet dâ€™extraire automatiquement la transcription dâ€™une vidÃ©o YouTube Ã  partir de son URL.  \n",
    "Elle identifie lâ€™ID de la vidÃ©o, interroge lâ€™API via la mÃ©thode `.fetch()` et formate le texte avec des horodatages `[MM:SS]`.  \n",
    "Elle prend Ã©galement en compte les cas dâ€™erreur courants (vidÃ©o privÃ©e, transcription dÃ©sactivÃ©e, etc.).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae153bb8-f625-4267-a182-db910c8143ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Transcript (impl Python robuste + outil exposÃ©)\n",
    "# =========================\n",
    "def fetch_youtube_transcript_impl(url: str) -> str:\n",
    "    \"\"\"RÃ©cupÃ¨re la transcription d'une vidÃ©o YouTube et la formate [MM:SS] texte.\n",
    "       Compatible dicts ET objets FetchedTranscriptSnippet.\n",
    "    \"\"\"\n",
    "    video_id_pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*'\n",
    "    match = re.search(video_id_pattern, url or \"\")\n",
    "    if not match:\n",
    "        return \"âš ï¸ URL YouTube invalide.\"\n",
    "\n",
    "    vid = match.group(1)\n",
    "    try:\n",
    "        ytt_api = YouTubeTranscriptApi()\n",
    "        transcript_data = None\n",
    "\n",
    "        # PrioritÃ© fr â†’ en â†’ dÃ©faut\n",
    "        try:\n",
    "            transcript_data = ytt_api.fetch(vid, languages=['fr'])\n",
    "        except NoTranscriptFound:\n",
    "            try:\n",
    "                transcript_data = ytt_api.fetch(vid, languages=['en'])\n",
    "            except NoTranscriptFound:\n",
    "                transcript_data = ytt_api.fetch(vid)\n",
    "\n",
    "        if not transcript_data:\n",
    "            return \"âŒ Aucune donnÃ©e de transcription rÃ©cupÃ©rÃ©e\"\n",
    "\n",
    "        lines = []\n",
    "        for entry in transcript_data:\n",
    "            try:\n",
    "                # Cas objet (FetchedTranscriptSnippet)\n",
    "                if hasattr(entry, \"start\") and hasattr(entry, \"text\"):\n",
    "                    start = float(entry.start)\n",
    "                    text = entry.text\n",
    "                # Cas dict (ancien format)\n",
    "                elif isinstance(entry, dict) and \"start\" in entry and \"text\" in entry:\n",
    "                    start = float(entry[\"start\"])\n",
    "                    text = entry[\"text\"]\n",
    "                else:\n",
    "                    # Fallback ultra-robuste\n",
    "                    start = float(getattr(entry, \"start\", 0.0))\n",
    "                    text = str(getattr(entry, \"text\", \"\"))\n",
    "\n",
    "                text = (text or \"\").strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "\n",
    "                m, s = int(start // 60), int(start % 60)\n",
    "                lines.append(f\"[{m:02d}:{s:02d}] {text}\")\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        if not lines:\n",
    "            return \"âŒ Transcription vide\"\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    except TranscriptsDisabled:\n",
    "        return \"âŒ Les transcriptions sont dÃ©sactivÃ©es pour cette vidÃ©o.\"\n",
    "    except VideoUnavailable:\n",
    "        return \"âŒ VidÃ©o non disponible.\"\n",
    "    except CouldNotRetrieveTranscript:\n",
    "        return \"âŒ Impossible de rÃ©cupÃ©rer la transcription.\"\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Erreur : {str(e)}\"\n",
    "\n",
    "# Exposer lâ€™outil pour lâ€™agent (function calling)\n",
    "from agents import function_tool\n",
    "fetch_youtube_transcript = function_tool(fetch_youtube_transcript_impl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a722c1-7884-4dcf-b9c9-989983cd771a",
   "metadata": {},
   "source": [
    "##  Agents IA (GPT-5) â€” Instructions hybrides\n",
    "\n",
    "### Agent 1 â€” Analyse\n",
    "- **RÃ´le** : Analyse un texte ou une URL YouTube.\n",
    "- **Si URL** : utilise `fetch_youtube_transcript` pour rÃ©cupÃ©rer le transcript.\n",
    "- **Sortie** :  \n",
    "  1. Points clÃ©s (5â€“8)  \n",
    "  2. Ton & intentions (2â€“3 phrases)  \n",
    "  3. Angles dâ€™email (2â€“3 lignes)  \n",
    "  4. RÃ©sumÃ© exÃ©cutif (120â€“180 mots)  \n",
    "- **ModÃ¨le** : `gpt-5`\n",
    "\n",
    "### Agent 2 â€” RÃ©ponse & RÃ©daction\n",
    "- **RÃ´le** : Utilise le transcript et lâ€™analyse pour :\n",
    "  - RÃ©pondre Ã  des questions factuelles\n",
    "  - GÃ©nÃ©rer un post LinkedIn (800â€“1200 car.) ou Instagram (300â€“600 car.)\n",
    "- **Outils** : aucun  \n",
    "- **ModÃ¨le** : `gpt-5`\n",
    "\n",
    "**Flux** : Utilisateur â†’ Agent 1 (analyse) â†’ Agent 2 (rÃ©ponse ou rÃ©daction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4e0269-efb4-4812-b37b-6db5e466565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#  Agents (GPT-5) avec instructions hybrides\n",
    "# =========================\n",
    "# Agent 1 â€” Analyse (outil en secours si URL sans transcript)\n",
    "AGENT1_INSTRUCTIONS = (\n",
    "    \"Tu es un analyste Ã©ditorial. \"\n",
    "    \"Tu peux recevoir soit un TEXTE directement, soit une URL YouTube. \"\n",
    "    \"Si on te donne une URL YouTube et qu'aucun transcript exploitable n'est fourni dans le message, \"\n",
    "    \"alors appelle l'outil fetch_youtube_transcript(url) pour rÃ©cupÃ©rer le transcript AVANT d'analyser. \"\n",
    "    \"Ensuite, retourne STRICTEMENT les blocs suivants, en franÃ§ais :\\n\"\n",
    "    \"1) Points clÃ©s (5â€“8, liste numÃ©rotÃ©e)\\n\"\n",
    "    \"2) Ton & intentions de lâ€™auteur (2â€“3 phrases)\\n\"\n",
    "    \"3) Angles dâ€™email possibles (2â€“3, une ligne chacun)\\n\"\n",
    "    \"4) RÃ©sumÃ© exÃ©cutif (120â€“180 mots)\\n\"\n",
    "    \"Ã‰vite les gÃ©nÃ©ralitÃ©s, ancre-toi dans le contenu. Ne rajoute pas dâ€™autre texte.\"\n",
    ")\n",
    "\n",
    "def create_agent_analyse():\n",
    "    return Agent(\n",
    "        name=\"Agent Analyse\",\n",
    "        instructions=AGENT1_INSTRUCTIONS,\n",
    "        tools=[fetch_youtube_transcript],  # âœ… outil dispo en backup\n",
    "        model=\"gpt-5\",\n",
    "    )\n",
    "\n",
    "# Agent 2 â€” RÃ©ponse & RÃ©daction\n",
    "AGENT2_INSTRUCTIONS = (\n",
    "    \"Tu es un assistant de rÃ©ponses et de rÃ©daction. On te donne :\\n\"\n",
    "    \"- le transcript ou le texte source (si disponible)\\n\"\n",
    "    \"- le livrable de lâ€™Agent Analyse (points clÃ©s, ton, angles, rÃ©sumÃ©)\\n\"\n",
    "    \"Tu dois :\\n\"\n",
    "    \"1) RÃ©pondre aux questions factuelles de lâ€™utilisateur en tâ€™appuyant sur le contenu, OU\\n\"\n",
    "    \"2) GÃ©nÃ©rer des contenus courts (post LinkedIn 800â€“1200 car., post Instagram 300â€“600 car.).\\n\"\n",
    "    \"Reste concret et fidÃ¨le au contenu.\"\n",
    ")\n",
    "\n",
    "def create_agent_responder():\n",
    "    return Agent(\n",
    "        name=\"Agent RÃ©ponse & RÃ©daction\",\n",
    "        instructions=AGENT2_INSTRUCTIONS,\n",
    "        tools=[],  # pas dâ€™outil ici\n",
    "        model=\"gpt-5\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0613404-9f71-4d8c-bd3b-092ddfdbc908",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9b02b6e-5691-4519-8ebd-ddfee03be50c",
   "metadata": {},
   "source": [
    "### Lancement de la boucle de dialogue avec l'utilisateur\n",
    "\n",
    "La fonction `main()` initialise et gÃ¨re lâ€™interaction en continu entre l'utilisateur et l'agent.\n",
    "\n",
    "#### Fonctionnement :\n",
    "- Affiche un message dâ€™accueil et attend une entrÃ©e utilisateur\n",
    "- GÃ¨re les commandes de sortie (`exit`, `quit`, etc.)\n",
    "- Stocke les Ã©changes dans une liste `input_items` pour maintenir le contexte\n",
    "- Limite lâ€™historique Ã  8 messages pour Ã©viter les dÃ©passements de capacitÃ© du modÃ¨le (token limit)\n",
    "- Transmet les Ã©changes Ã  lâ€™agent via `Runner.run_streamed(...)` pour obtenir une rÃ©ponse en streaming\n",
    "- GÃ¨re les diffÃ©rents types dâ€™Ã©vÃ©nements retournÃ©s : texte gÃ©nÃ©rÃ©, appel dâ€™outil, rÃ©sultats dâ€™outil\n",
    "- Affiche la rÃ©ponse en temps rÃ©el ligne par ligne\n",
    "\n",
    "Cette boucle permet de simuler une vÃ©ritable conversation, tout en exploitant les capacitÃ©s du modÃ¨le GPT-4o et de lâ€™outil `fetch_youtube_transcript` si nÃ©cessaire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46fa45f-00e9-487d-bee7-92aff63cc13d",
   "metadata": {},
   "source": [
    "# Orchestrateur :\n",
    " - SessionState : stocke transcript, analyse, type de source\n",
    " - prepare_source : rÃ©cupÃ¨re transcript cÃ´tÃ© Python si possible, sinon garde texte brut\n",
    " - run_analysis_pipeline : lance Agent 1 (analyse) avec transcript ou URL\n",
    " - ask_with_context : lance Agent 2 (rÃ©ponse/rÃ©daction) avec transcript + analyse + demande\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5498a1c-1429-4420-bb76-fdb34857d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#  Orchestration automatique (analyse + livrables)\n",
    "# =========================\n",
    "\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "def force_json_prompt():\n",
    "    return (\n",
    "        \"Tu dois produire STRICTEMENT un JSON compact (une seule ligne), sans commentaire, sans texte avant/aprÃ¨s.\\n\"\n",
    "        \"SchÃ©ma attendu:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"points_cles\": [\"\", \"\", \"\", \"\", \"\"],\\n'\n",
    "        '  \"post_linkedin\": \"\"\\n'\n",
    "        \"}\\n\"\n",
    "        \"- points_cles : exactement 5 Ã©lÃ©ments, concis, factuels, fidÃ¨les au contenu dâ€™Agent 1.\\n\"\n",
    "        \"- post_linkedin : ~900 caractÃ¨res, franÃ§ais, structurÃ© (accroche, dÃ©veloppement, conclusion/CTA), lisible, sans hashtags superflus.\\n\"\n",
    "        \"Ne renvoie surtout pas de Markdown ni de texte hors JSON.\"\n",
    "    )\n",
    "\n",
    "async def run_full_pipeline(text_or_url: str):\n",
    "    # 1) Analyse (Agent 1)\n",
    "    analysis = await run_analysis_pipeline(text_or_url)\n",
    "    if not analysis or analysis.startswith(\"âŒ\"):\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error\": analysis or \"Analyse vide.\",\n",
    "            \"points_cles\": [],\n",
    "            \"post_linkedin\": \"\"\n",
    "        }\n",
    "\n",
    "    # 2) Agent 2 â€” consigne stricte pour renvoyer un JSON (points_cles + post_linkedin)\n",
    "    strict_json_instr = force_json_prompt()\n",
    "    user_task = (\n",
    "        \"Ã€ partir du transcript/texte et de l'analyse ci-dessus, fais ceci :\\n\"\n",
    "        \"1) Donne-moi un rÃ©sumÃ© clair en **5 points** (courts, factuels, sans jargon inutile).\\n\"\n",
    "        \"2) Propose un **post LinkedIn** autour de 900 caractÃ¨res, structurÃ© (accroche â†’ idÃ©e centrale â†’ appel Ã  lâ€™action), ton pro, sans emojis excessifs.\\n\\n\"\n",
    "        \"Respecte le format JSON imposÃ© ci-dessous.\"\n",
    "    )\n",
    "    full_context = (\n",
    "        \"=== TRANSCRIPT / TEXTE ===\\n\" + (state.transcript[:12000] or \"\") + \"\\n\\n\"\n",
    "        \"=== ANALYSE (Agent 1) ===\\n\" + (analysis[:12000] or \"\") + \"\\n\\n\"\n",
    "        \"=== DEMANDE UTILISATEUR ===\\n\" + user_task + \"\\n\\n\"\n",
    "        \"=== FORMAT ===\\n\" + strict_json_instr\n",
    "    )\n",
    "\n",
    "    res = await Runner.run(\n",
    "        create_agent_responder(),\n",
    "        input=[{\"role\": \"user\", \"content\": full_context}]\n",
    "    )\n",
    "    raw = extract_run_text(res).strip()\n",
    "\n",
    "    # 3) Parsing JSON robuste (tolÃ©rance aux entÃªtes/markdown)\n",
    "    def try_extract_json(s: str):\n",
    "        # essaie de trouver le premier { ... } Ã©quilibrÃ©\n",
    "        start = s.find(\"{\")\n",
    "        end = s.rfind(\"}\")\n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            candidate = s[start:end+1].strip()\n",
    "            try:\n",
    "                return json.loads(candidate)\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        # dernier recours : tenter directement\n",
    "        try:\n",
    "            return json.loads(s)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    payload = try_extract_json(raw)\n",
    "    if not payload or not isinstance(payload, dict):\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error\": \"Sortie Agent 2 non parsable en JSON.\",\n",
    "            \"raw\": raw,\n",
    "            \"points_cles\": [],\n",
    "            \"post_linkedin\": \"\"\n",
    "        }\n",
    "\n",
    "    points = payload.get(\"points_cles\") or []\n",
    "    post = payload.get(\"post_linkedin\") or \"\"\n",
    "    if not isinstance(points, list):\n",
    "        points = []\n",
    "    if not isinstance(post, str):\n",
    "        post = \"\"\n",
    "\n",
    "    return {\n",
    "        \"status\": \"ok\",\n",
    "        \"analysis_excerpt\": analysis[:1200],\n",
    "        \"points_cles\": points[:5],  # on limite Ã  5 si plus\n",
    "        \"post_linkedin\": post.strip()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bccb551b-402e-40e6-ba02-43ba35685b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_analysis_pipeline(text_or_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Lance l'analyse avec Agent 1.\n",
    "    - Si transcript Python disponible, l'utilise directement\n",
    "    - Sinon, passe l'URL brute pour que l'agent appelle l'outil\n",
    "    - Retourne les 4 blocs attendus et les stocke dans state.analysis\n",
    "    \"\"\"\n",
    "    user_msg = (text_or_url or \"\").strip()\n",
    "    if not user_msg:\n",
    "        return \"âŒ Aucun contenu.\"\n",
    "\n",
    "    # PrÃ©pare la source : transcript ou texte brut\n",
    "    source_text = prepare_source(user_msg)\n",
    "    a1 = create_agent_analyse()\n",
    "\n",
    "    # Cas A : transcript rÃ©cupÃ©rÃ© cÃ´tÃ© Python\n",
    "    if source_text and not source_text.startswith((\"âŒ\", \"âš ï¸\")):\n",
    "        prompt = f\"Analyse ce contenu et renvoie les 4 blocs demandÃ©s :\\n\\n{source_text}\"\n",
    "        items = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    else:\n",
    "        # Cas B : aucun transcript â†’ l'agent devra appeler lâ€™outil\n",
    "        items = [{\"role\": \"user\", \"content\": user_msg}]\n",
    "\n",
    "    # ExÃ©cution (non-streaming)\n",
    "    res = await Runner.run(a1, input=items)\n",
    "    analysis = extract_run_text(res).strip()\n",
    "\n",
    "    # Stockage\n",
    "    state.analysis = analysis if analysis else None\n",
    "    return analysis if analysis else \"âŒ Analyse vide.\"\n",
    "\n",
    "\n",
    "async def ask_with_context(user_question_or_task: str) -> str:\n",
    "    \"\"\"\n",
    "    Lance Agent 2 pour rÃ©pondre ou rÃ©diger Ã  partir :\n",
    "    - du transcript ou texte brut\n",
    "    - de l'analyse produite par Agent 1\n",
    "    - de la question / consigne utilisateur\n",
    "    \"\"\"\n",
    "    if not state.transcript:\n",
    "        return \"âŒ Aucun transcript/texte source disponible. Lance dâ€™abord lâ€™analyse.\"\n",
    "    if not state.analysis:\n",
    "        return \"âŒ Aucune analyse disponible. Lance dâ€™abord lâ€™analyse.\"\n",
    "\n",
    "    a2 = create_agent_responder()\n",
    "\n",
    "    # Construit le contexte complet\n",
    "    context = (\n",
    "        \"=== TRANSCRIPT / TEXTE ===\\n\" + (state.transcript[:12000] or \"\") + \"\\n\\n\"\n",
    "        \"=== ANALYSE (Agent 1) ===\\n\" + (state.analysis[:12000] or \"\") + \"\\n\\n\"\n",
    "        \"=== DEMANDE UTILISATEUR ===\\n\" + (user_question_or_task or \"\")\n",
    "    )\n",
    "\n",
    "    # ExÃ©cution (non-streaming)\n",
    "    res = await Runner.run(a2, input=[{\"role\": \"user\", \"content\": context}])\n",
    "    return extract_run_text(res).strip() or \"âŒ RÃ©ponse vide.\"\n",
    "\n",
    "\n",
    "class SessionState:\n",
    "    def __init__(self):\n",
    "        self.transcript = None   # texte transcript/texte brut retenu\n",
    "        self.analysis = None     # sortie Agent 1\n",
    "        self.source_kind = None  # \"url\" ou \"text\"\n",
    "\n",
    "state = SessionState()\n",
    "\n",
    "\n",
    "def is_youtube_url(s: str) -> bool:\n",
    "    \"\"\"DÃ©tecte si une chaÃ®ne est une URL YouTube.\"\"\"\n",
    "    return bool(s) and (\"youtu.be/\" in s or \"youtube.com/watch\" in s)\n",
    "\n",
    "\n",
    "def prepare_source(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    PrÃ©pare la source pour l'analyse.\n",
    "    - Si URL YouTube â†’ tente de rÃ©cupÃ©rer transcript cÃ´tÃ© Python\n",
    "    - Sinon â†’ texte brut\n",
    "    \"\"\"\n",
    "    user_input = (user_input or \"\").strip()\n",
    "    if not user_input:\n",
    "        return \"\"\n",
    "\n",
    "    if is_youtube_url(user_input):\n",
    "        state.source_kind = \"url\"\n",
    "        # Ici, on appelle ton implÃ©mentation Python directe de transcript\n",
    "        txt = fetch_youtube_transcript_impl(user_input)  \n",
    "        state.transcript = txt\n",
    "        return txt\n",
    "\n",
    "    state.source_kind = \"text\"\n",
    "    state.transcript = user_input\n",
    "    return user_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c8479a-ffb1-45ea-908f-94884669de86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALYSE (Agent 1) â€” extrait ===\n",
      "1) Points clÃ©s\n",
      "1. Trois tests concrets sur un dataset de churn: analyse exploratoire, modÃ©lisation ML, et crÃ©ation dâ€™une app Shiny â€œend-to-endâ€.\n",
      "2. Test 1 (analyse): GPTâ€‘5 a importÃ© la data (pandas), fait des stats descriptives, tentÃ© un modÃ¨le baseline, identifiÃ© des drivers (gÃ©ographie, activitÃ©, Ã¢ge, genre) et fourni un rapport Excel; mais peu de visualisations et confusion initiale sur la cible; note: 5/10. Claude 4.1: livrable visuellement sÃ©duisant mais analyses manquantes.\n",
      "3. Test 2 (modÃ©lisation): GPTâ€‘5 a livrÃ© un pipeline Python (OneHotEncoder, StandardScaler, LogisticRegression), split stratifiÃ©, score ~83,7% en test, export du modÃ¨le en .joblib + README de dÃ©ploiement, et propose dâ€™essayer dâ€™autres algos; note: 5/10 (rapport et justifications insuffisants). Claude: surtout de lâ€™HTML/design et une liste dâ€™algos, pas dâ€™exÃ©cution; 1/10 â€œpour la beautÃ©â€.\n",
      "4. Test 3 (app Shiny R): structure complÃ¨te (import, EDA, prÃ©traitement, modÃ©lisation, Ã©valuation, explicabilitÃ©, scoring, export). Les deux IA gÃ©nÃ¨rent du code mais butent sur des erreurs; GPTâ€‘5 corrige aprÃ¨s indications, problÃ¨mes de packages; Claude atteint des limites de longueur et nâ€™achÃ¨ve pas sans guidage.\n",
      "5. Constat:\n",
      "\n",
      "=== RÃ‰PONSE (Agent 2) â€” extrait ===\n",
      "Voici le rÃ©sumÃ© en 5 points:\n",
      "- Dispositif: cas rÃ©el de churn, 3 tÃ¢ches (analyse exploratoire, modÃ©lisation, app Shiny), dâ€™abord sans consignes puis avec; comparaison GPTâ€‘5 vs Claude 4.1.\n",
      "- Analyse exploratoire: GPTâ€‘5 gÃ©nÃ¨re code Python (pandas), descriptifs et quelques viz mais hÃ©site sur la cible; rapport perfectible â†’ 5/10. Claude: rendu joli, peu dâ€™insights actionnables.\n",
      "- ModÃ©lisation: GPTâ€‘5 livre un pipeline (OneHotEncoder+StandardScaler+LogisticRegression), split stratifiÃ©, ~83,7% en test, export .joblib + README â†’ utile mais rapport et justifs faibles â†’ 5/10. Claude: surtout du design/HTML â†’ 1/10.\n",
      "- App Shiny endâ€‘toâ€‘end: les deux produisent du code, mais erreurs, dÃ©pendances et besoin de guidage; pas â€œproduction readyâ€ sans expertise.\n",
      "- Verdict: lâ€™IA accÃ©lÃ¨re et dÃ©mocratise, mais ne remplace pas la rigueur/mÃ©thodo/stratÃ©gie dâ€™unÂ·e expertÂ·e. Le code devient une commoditÃ©; la valeur est dans le cadrage, lâ€™Ã©valuation, lâ€™explicabilitÃ© et le dÃ©ploiement. Suite: vidÃ©o mode agentique + Bootcamp GNI Pro (8 semaines dÃ¨s le 15/09).\n",
      "\n",
      "Post LinkedIn (~900 caractÃ¨res):\n",
      "GPTâ€‘5 vaâ€‘tâ€‘il remplacer les data analysts/scientists ? Je lâ€™ai testÃ© sur un vrai cas de churn, face Ã  Claude 4.1, sur 3 tÃ¢ches (sans consignes puis guidÃ©es): EDA, modÃ©lisation, app Shiny endâ€‘toâ€‘end.\n",
      "\n",
      "RÃ©sultats:\n",
      "- EDA: GPTâ€‘5 produit code (pandas) et descriptifs, mais hÃ©site sur la cible et peu de viz â†’ 5/10. Claude: beau rendu, peu dâ€™insights.\n",
      "- ModÃ©lisation: pipeline (OneHotEncoder+StandardScaler+LogisticRegression), split stratifiÃ©, ~83,7% en test, export .joblib + README â†’ utile mais rapport pauvre â†’ 5/10. Claude:\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# DÃ©mo rapide\n",
    "# =========================\n",
    "SOURCE_INPUT = \"https://www.youtube.com/watch?v=vOmo-Q7RrRc&t=643s\"  # remplace par une URL transcriptible ou colle un texte\n",
    "\n",
    "analysis = await run_analysis_pipeline(SOURCE_INPUT)\n",
    "print(\"=== ANALYSE (Agent 1) â€” extrait ===\")\n",
    "print((analysis or \"\")[:1200])\n",
    "\n",
    "QUESTION_OR_TASK = \"Donne-moi un rÃ©sumÃ© clair en 5 points, puis propose un post LinkedIn (~900 caractÃ¨res).\"\n",
    "answer = await ask_with_context(QUESTION_OR_TASK)\n",
    "print(\"\\n=== RÃ‰PONSE (Agent 2) â€” extrait ===\")\n",
    "print((answer or \"\")[:1600])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db1009-db50-490f-99d9-4347d2763b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multi-Agents YouTube â€” GPT-4o (non-streaming) ===\n",
      "Collez une URL YouTube (ou un texte long) â†’ je lance lâ€™analyse + points clÃ©s + post LinkedIn automatiquement.\n",
      "Ensuite, tapez une courte question/consigne â†’ je rÃ©ponds avec lâ€™Agent 2.\n",
      "Tapez 'exit' pour quitter.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  https://www.youtube.com/watch?v=7-FFFjlLwos\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# ðŸ’¬ Cellule 8 â€” Mini chat (AUTO orchestration)\n",
    "# =========================\n",
    "import textwrap\n",
    "\n",
    "DEBUG = True\n",
    "MAX_PREVIEW = 1500\n",
    "\n",
    "def _looks_like_url(s: str) -> bool:\n",
    "    s = (s or \"\").strip().lower()\n",
    "    return s.startswith(\"http://\") or s.startswith(\"https://\")\n",
    "\n",
    "def _is_youtube_url(s: str) -> bool:\n",
    "    s = (s or \"\").strip().lower()\n",
    "    return \"youtu.be/\" in s or \"youtube.com/watch\" in s\n",
    "\n",
    "def _looks_like_long_text(s: str) -> bool:\n",
    "    # Heuristique simple pour dÃ©clencher l'analyse sur un texte â€œlongâ€\n",
    "    return len((s or \"\").strip()) >= 200\n",
    "\n",
    "async def chat_loop():\n",
    "    print(\"=== Multi-Agents YouTube â€” GPT-5 ===\")\n",
    "    print(\"Collez une URL YouTube (ou un texte long) â†’ je lance lâ€™analyse + points clÃ©s + post LinkedIn automatiquement.\")\n",
    "    print(\"Ensuite, tapez une courte question/consigne â†’ je rÃ©ponds avec lâ€™Agent 2.\")\n",
    "    print(\"Tapez 'exit' pour quitter.\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user = await asyncio.to_thread(input, \"\\nYou: \")\n",
    "        except (EOFError, KeyboardInterrupt):\n",
    "            print(\"\\nBye.\")\n",
    "            break\n",
    "\n",
    "        if not user:\n",
    "            continue\n",
    "        cmd_raw = user.strip()\n",
    "        cmd = cmd_raw.lower()\n",
    "\n",
    "        # Quitter\n",
    "        if cmd in (\"exit\", \"quit\", \"bye\"):\n",
    "            print(\"ðŸ‘‹ Ã€ bientÃ´t !\")\n",
    "            break\n",
    "\n",
    "        # 1) Si c'est une URL (YouTube ou autre) OU un texte suffisamment long â†’ orchestration complÃ¨te\n",
    "        if _looks_like_url(cmd_raw) or _is_youtube_url(cmd_raw) or _looks_like_long_text(cmd_raw):\n",
    "            # Orchestration automatique (Agent 1 â†’ Agent 2)\n",
    "            result = await run_full_pipeline(cmd_raw)\n",
    "            if result.get(\"status\") != \"ok\":\n",
    "                print(\"âŒ Pipeline Ã©chouÃ© :\", result.get(\"error\", \"Erreur inconnue\"))\n",
    "                if result.get(\"raw\"):\n",
    "                    print(\"\\n--- Sortie brute Agent 2 (debug) ---\\n\")\n",
    "                    print(result[\"raw\"][:2000])\n",
    "            else:\n",
    "                print(\"\\n=== Agent 1 â€” Analyse (extrait) ===\")\n",
    "                print(result[\"analysis_excerpt\"])\n",
    "\n",
    "                print(\"\\n=== Agent 2 â€” RÃ©sultat 1/2 : Points clÃ©s ===\")\n",
    "                if result[\"points_cles\"]:\n",
    "                    for i, p in enumerate(result[\"points_cles\"], 1):\n",
    "                        print(f\"{i}. {p}\")\n",
    "                else:\n",
    "                    print(\"Aucun point clÃ© parsÃ©.\")\n",
    "\n",
    "                print(\"\\n=== Agent 2 â€” RÃ©sultat 2/2 : Post LinkedIn (~900 car.) ===\")\n",
    "                if result[\"post_linkedin\"]:\n",
    "                    print(textwrap.fill(result[\"post_linkedin\"], width=100))\n",
    "                else:\n",
    "                    print(\"Post LinkedIn vide ou non parsÃ©.\")\n",
    "            continue\n",
    "\n",
    "        # 2) Sinon : courte question/consigne â†’ Agent 2 (si on a dÃ©jÃ  une analyse)\n",
    "        if state.transcript and state.analysis:\n",
    "            resp = await ask_with_context(cmd_raw)\n",
    "            if resp.startswith(\"âŒ\"):\n",
    "                print(\"\\n[Agent 2 â€” ERREUR]\")\n",
    "                print(resp)\n",
    "            else:\n",
    "                print(\"\\n[Agent 2 â€” RÃ‰PONSE] (aperÃ§u)\")\n",
    "                print(resp[:MAX_PREVIEW] + (\"\\nâ€¦[tronquÃ©]\" if len(resp) > MAX_PREVIEW else \"\"))\n",
    "        else:\n",
    "            print(\"\\nâ„¹ï¸ Collez dâ€™abord une URL YouTube (ou un texte long â‰¥ 200 caractÃ¨res).\")\n",
    "            print(\"Je lancerai automatiquement lâ€™analyse + les points clÃ©s + le post LinkedIn.\")\n",
    "\n",
    "# Lance la boucle :\n",
    "await chat_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335108d-a266-409d-9022-9674573c5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e9738-e5de-4b49-93e4-540e3683c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pipreqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f2ce8-fcff-4ba1-a977-657a311e2cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b25f2-3029-4a3b-8874-c6db9a3d9479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2-env)",
   "language": "python",
   "name": "tf2-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
