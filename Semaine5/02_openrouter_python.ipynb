{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9ff00a",
   "metadata": {},
   "source": [
    "\n",
    "# OpenRouter x Python \n",
    "\n",
    "\n",
    "Objectif : appeler **OpenRouter** depuis Python en lisant la clé **depuis `.env`** (variable `OPENROUTER_API_KEY`).  \n",
    "Nous montrons :\n",
    "1. Chargement des variables d'environnement\n",
    "2. Appel **non-streaming** (simple)\n",
    "3. Appel **streaming** (ligne par ligne)\n",
    "\n",
    "> Prérequis : créer un fichier `.env` à la racine de votre projet contenant :  \n",
    "> `OPENROUTER_API_KEY=sk-...`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783c354",
   "metadata": {},
   "source": [
    "## 0) Dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Décommentez si besoin\n",
    "# !pip install requests python-dotenv -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aac5d7",
   "metadata": {},
   "source": [
    "## 1) Charger la clé API depuis `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6b528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clé détectée (tronquée) : sk-or-v1...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Charge .env\n",
    "load_dotenv()\n",
    "\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "assert OPENROUTER_API_KEY, \"La variable d'environnement OPENROUTER_API_KEY est absente. Ajoutez-la dans votre .env\"\n",
    "print(\"Clé détectée (tronquée) :\", OPENROUTER_API_KEY[:8] + \"...\" if OPENROUTER_API_KEY else \"Aucune\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d4000",
   "metadata": {},
   "source": [
    "## 2) Paramètres simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf30bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle : meta-llama/llama-3.1-70b-instruct\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "OPENROUTER_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "# Choisissez un modèle auquel votre compte a accès.\n",
    "# Exemples fréquents (selon disponibilités) :\n",
    "# - \"meta-llama/llama-3.1-70b-instruct\"\n",
    "# - \"anthropic/claude-3.5-sonnet\"\n",
    "# - \"openai/gpt-4o-mini\"\n",
    "# - \"mistralai/mixtral-8x7b-instruct\"\n",
    "MODEL = \"meta-llama/llama-3.1-70b-instruct\"  # <— changez si nécessaire\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    # Optionnel mais recommandé par OpenRouter (aide à l'attribution & au support)\n",
    "    \"HTTP-Referer\": \"https://your-site-or-github.com\",\n",
    "    \"X-Title\": \"OpenRouter Minimal Notebook\",\n",
    "}\n",
    "print(\"Modèle :\", MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20385938",
   "metadata": {},
   "source": [
    "## 3) Appel \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a6ef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Content-Type: application/json\n",
      "\n",
      "Réponse :\n",
      " Un LLM (Large Language Model) est un modèle d'intelligence artificielle entraîné sur de grandes quantités de données textuelles pour générer du texte cohérent et réaliste, capable de comprendre et de répondre à des questions ou à des requêtes. Un exemple concret d'utilisation d'un LLM est un chatbot de support client, comme celui utilisé par une entreprise pour répondre automatiquement aux questions fréquentes des clients et fournir des informations sur ses produits ou services.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "payload = {\n",
    "    \"model\": MODEL,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Tu es un assistant concis et pédagogique.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explique en 2 phrases ce qu'est un LLM et donne un cas d'usage concret.\"}\n",
    "    ],\n",
    "    \"stream\": False  # on veut une seule réponse JSON\n",
    "}\n",
    "\n",
    "r = requests.post(OPENROUTER_URL, headers=headers, json=payload)\n",
    "print(\"Status:\", r.status_code)\n",
    "print(\"Content-Type:\", r.headers.get(\"Content-Type\"))\n",
    "\n",
    "data = r.json()  # ok parce que stream=False => un seul JSON\n",
    "# La réponse standard suit la structure OpenAI-like:\n",
    "# data[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(\"\\nRéponse :\\n\", data[\"choices\"][0][\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7329c8",
   "metadata": {},
   "source": [
    "## 4) Appel **streaming** (ligne par ligne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b13fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici 4 bonnes pratiques pour écrire un prompt efficace :\n",
      "\n",
      "1.  **Soyez précis** : Définissez clairement ce que vous voulez obtenir en réponse. Évitez les questions ou les demandes vagues.\n",
      "\n",
      "2.  **Soyez concis** : Plus votre prompt sera court et concis, plus il sera facile à comprendre et à traiter.\n",
      "\n",
      "3.  **Utilisez des mots-clés** : Les mots-clés aident à spécifier le contexte et la direction que vous voulez donner à la réponse.\n",
      "\n",
      "4.  **Soyez spécifique** : Donnez suffisamment de détails pour que la réponse soit pertinente et utile.\n",
      "— Fin du streaming —\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "payload_stream = {\n",
    "    \"model\": MODEL,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"Tu es un assistant concis et pédagogique.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Donne 4 bonnes pratiques pour écrire un prompt efficace.\"}\n",
    "    ],\n",
    "    \"stream\": True  # renverra un flux d'events JSON (SSE/NDJSON)\n",
    "}\n",
    "\n",
    "with requests.post(OPENROUTER_URL, headers=headers, json=payload_stream, stream=True) as resp:\n",
    "    resp.raise_for_status()\n",
    "    for line in resp.iter_lines():\n",
    "        if not line:\n",
    "            continue\n",
    "        # OpenRouter envoie des events commençant souvent par 'data: {json}'\n",
    "        raw = line.decode(\"utf-8\")\n",
    "        if not raw.startswith(\"data:\"):\n",
    "            continue\n",
    "        raw = raw[len(\"data:\"):].strip()\n",
    "        if raw == \"[DONE]\":\n",
    "            break\n",
    "        try:\n",
    "            event = json.loads(raw)\n",
    "            delta = event.get(\"choices\", [{}])[0].get(\"delta\", {}).get(\"content\", \"\")\n",
    "            if delta:\n",
    "                print(delta, end=\"\")\n",
    "        except json.JSONDecodeError:\n",
    "            # ignore les lignes non-JSON (keep-alive, etc.)\n",
    "            pass\n",
    "print(\"\\n— Fin du streaming —\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1baa44",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
